{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arXiv:1608.03981v1 [cs.CV] 13 Aug 2016#\n",
    "# Beyond a Gaussian Denoiser: Residual Learning of\n",
    "# Deep CNN for Image Denoising\n",
    "# Kai Zhang, Wangmeng Zuo, Yunjin Chen, Deyu Meng, and Lei Zhang\n",
    "# \n",
    "# Author: Olaf Christ\n",
    "# Email: christ_o@gmx.de\n",
    "# DnCNN model\n",
    "\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import  Input,Conv2D,BatchNormalization,Activation, Subtract, SpatialDropout2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "#from keras import backend as K\n",
    "\n",
    "#this fixes issues present on my system\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "#This fixes issues with cuDNN\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "InteractiveSession(config=config).close()\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "#this fixes out of memory errors\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K \n",
    "import gc\n",
    "K.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "class DnCNN(object):\n",
    "    def __init__(self,\n",
    "                 useDropout = False, \n",
    "                 activation = 'relu',\n",
    "                 dropout_rate = 0.2,\n",
    "                 depth = 5,\n",
    "                 kernel_size = (3, 3),\n",
    "                 strides=(1, 1),\n",
    "                 padding = 'same',\n",
    "                 data_format=\"channels_last\",\n",
    "                 dilation_rate=(1, 1),\n",
    "                 kernel_initializer='he_normal'):\n",
    "                \n",
    "                self.useDropout = useDropout\n",
    "                self.depth = depth\n",
    "                self.kernel_size = kernel_size\n",
    "                self.strides = strides\n",
    "                self.dropout_rate = dropout_rate\n",
    "                self.activation = activation\n",
    "                self.padding = padding\n",
    "                self.data_format = data_format\n",
    "                self.dilation_rate = dilation_rate\n",
    "\n",
    "    def build(self, anInput):\n",
    "        \n",
    "                x = Conv2D(filters=64, kernel_size=self.kernel_size, strides=self.strides, padding=self.padding)(anInput)\n",
    "                x = Activation(self.activation)(x)\n",
    "                for i in range(self.depth):\n",
    "                        x = Conv2D(filters = 64,\n",
    "                               kernel_size = self.kernel_size,\n",
    "                               strides= self.strides,\n",
    "                               padding= self.padding,\n",
    "                               data_format=self.data_format,\n",
    "                               dilation_rate=self.dilation_rate)(x)\n",
    "                        if self.useDropout:\n",
    "                            x = SpatialDropout2D(self.dropout_rate)(x)    \n",
    "                        x = BatchNormalization(axis=-1, epsilon=1e-3)(x)\n",
    "                        x = Activation(self.activation)(x)   \n",
    "\n",
    "                x = Conv2D(filters = 1,\n",
    "                               kernel_size = self.kernel_size,\n",
    "                               strides= self.strides,\n",
    "                               padding= self.padding,\n",
    "                               data_format=self.data_format,\n",
    "                               dilation_rate=self.dilation_rate)(x)\n",
    "                if self.useDropout:\n",
    "                    x = SpatialDropout2D(self.dropout_rate)(x)\n",
    "                x = Subtract()([anInput, x])# subtract noise\n",
    "                model = Model(inputs=anInput, outputs=x)    \n",
    "                return model            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# arXiv:1608.03981v1 [cs.CV] 13 Aug 2016#\n",
    "# Beyond a Gaussian Denoiser: Residual Learning of\n",
    "# Deep CNN for Image Denoising\n",
    "# Kai Zhang, Wangmeng Zuo, Yunjin Chen, Deyu Meng, and Lei Zhang\n",
    "# \n",
    "# Author: Olaf Christ\n",
    "# Email: christ_o@gmx.de\n",
    "# Train the DnCNN on MNIST\n",
    "# \n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# the code to load the MNIST dataset is adapted from\n",
    "# https://www.machinecurve.com/index.php/2019/12/20/building-an-image-denoiser-with-a-keras-autoencoder-neural-network/\n",
    "img_width, img_height = 28, 28\n",
    "noise_factor = 0.75\n",
    "\n",
    "# Load MNIST dataset\n",
    "(input_train, target_train), (input_test, target_test) = mnist.load_data()\n",
    "\n",
    "input_train = input_train.reshape(input_train.shape[0], img_width, img_height, 1)\n",
    "input_test = input_test.reshape(input_test.shape[0], img_width, img_height, 1)\n",
    "input_shape = (img_width, img_height, 1)\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Add noise\n",
    "pure = input_train\n",
    "pure_test = input_test\n",
    "noise = np.random.normal(0, 1, pure.shape)\n",
    "noise_test = np.random.normal(0, 1, pure_test.shape)\n",
    "noisy_input = pure + noise_factor * noise\n",
    "noisy_input_test = pure_test + noise_factor * noise_test\n",
    "batch_size = 8\n",
    "\n",
    "# Network parameters\n",
    "INPUT_SHAPE = (img_width, img_height, 1)\n",
    "inputs = Input(shape=INPUT_SHAPE, name='encoder_input')\n",
    "aDnCNN = DnCNN()\n",
    "denoisingCNNModel = aDnCNN.build(anInput = inputs)\n",
    "denoisingCNNModel.summary()\n",
    "denoisingCNNModel.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "#stop training if val_accuracy doesn't improve for 10 epochs.\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', mode='max', patience=10)\n",
    "\n",
    "# Train the autoencoder\n",
    "history = denoisingCNNModel.fit(noisy_input, pure,\n",
    "                validation_split=0.2,\n",
    "                epochs=15,\n",
    "                batch_size=batch_size,\n",
    "                callbacks=[earlystop_callback])\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "number_of_visualizations = 4\n",
    "\n",
    "# Generate denoised images\n",
    "samples = noisy_input_test[:number_of_visualizations]\n",
    "targets = target_test[:number_of_visualizations]\n",
    "denoised_images = denoisingCNNModel.predict(samples)\n",
    "\n",
    "# Plot denoised images\n",
    "for i in range(0, number_of_visualizations):\n",
    "  # Get the sample and the reconstruction\n",
    "      noisy_image = noisy_input_test[i][:, :, 0]\n",
    "      pure_image  = pure_test[i][:, :, 0]\n",
    "      denoised_image = denoised_images[i][:, :, 0]\n",
    "      input_class = targets[i]\n",
    "      # Matplotlib preparations\n",
    "      fig, axes = plt.subplots(1, 3)\n",
    "      fig.set_size_inches(8, 3.5)\n",
    "      # Plot sample and reconstruciton\n",
    "      axes[0].imshow(noisy_image)\n",
    "      axes[0].set_title('Noisy image')\n",
    "      axes[1].imshow(pure_image)\n",
    "      axes[1].set_title('Pure image')\n",
    "      axes[2].imshow(denoised_image)\n",
    "      axes[2].set_title('Denoised image')\n",
    "      fig.suptitle(f'MNIST target = {input_class}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arXiv:1608.03981v1 [cs.CV] 13 Aug 2016#\n",
    "# Beyond a Gaussian Denoiser: Residual Learning of\n",
    "# Deep CNN for Image Denoising\n",
    "# Kai Zhang, Wangmeng Zuo, Yunjin Chen, Deyu Meng, and Lei Zhang\n",
    "# \n",
    "# Author: Olaf Christ\n",
    "# Email: christ_o@gmx.de\n",
    "# Copyright (C) Olaf Christ 2020, All rights reserved\n",
    "#\n",
    "# Train the DnCNN on 256x256 patches randomly extracted from a few pictures\n",
    "# \n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction import image\n",
    "from tensorflow.keras.preprocessing import image as tf_Image\n",
    "from PIL import Image as pil_image\n",
    "\n",
    "def trainingDatagenerator(y_, batch_size=8):\n",
    "    \n",
    "    # y_ are the clean images\n",
    "    indices = list(range(y_.shape[0]))\n",
    "    while(True):\n",
    "        np.random.shuffle(indices)\n",
    "        for i in range(0, len(indices), batch_size):\n",
    "            batch_y = y_[indices[i:i+batch_size]]\n",
    "            noise =  np.random.normal(0, 1, batch_y.shape)\n",
    "            batch_x = batch_y + noise  #add some noise to the clean batch\n",
    "            yield batch_x, batch_y\n",
    "            \n",
    "#take a few images and randomly sample patches from those images\n",
    "TRAIN_IMAGES = glob.glob('./monkey_images/fullImagesGrayscale/*.jpg')\n",
    "training_data_clean = np.zeros((4000, 256, 256, 1))\n",
    "\n",
    "#prepare clean data \n",
    "cnt = 0\n",
    "for i, fig in enumerate(TRAIN_IMAGES):\n",
    "    one_image = tf_Image.load_img(fig, color_mode='grayscale')\n",
    "    custom_image = tf_Image.img_to_array(one_image).astype('float32')\n",
    "    random_patches = image.extract_patches_2d(custom_image, (256, 256), max_patches = 1000)\n",
    "    for x in range(1000):\n",
    "        img = pil_image.fromarray(random_patches[x])\n",
    "        data = tf_Image.img_to_array(img).astype('float32')\n",
    "        data = data/256.0\n",
    "        training_data_clean[x+cnt] = data\n",
    "    cnt = cnt + 1000   \n",
    "\n",
    "# Network parameters\n",
    "INPUT_SHAPE = (256, 256, 1)\n",
    "inputs = Input(shape=INPUT_SHAPE, name='encoder_input')\n",
    "aDnCNN = DnCNN()\n",
    "denoisingCNNModel = aDnCNN.build(anInput = inputs)\n",
    "denoisingCNNModel.summary()\n",
    "denoisingCNNModel.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "history = denoisingCNNModel.fit(trainingDatagenerator(training_data_clean), steps_per_epoch=len(training_data_clean)//8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# arXiv:1608.03981v1 [cs.CV] 13 Aug 2016#\n",
    "# Beyond a Gaussian Denoiser: Residual Learning of\n",
    "# Deep CNN for Image Denoising\n",
    "# Kai Zhang, Wangmeng Zuo, Yunjin Chen, Deyu Meng, and Lei Zhang\n",
    "# \n",
    "# Author: Olaf Christ\n",
    "# Email: christ_o@gmx.de\n",
    "# Copyright (C) Olaf Christ 2020, All rights reserved\n",
    "#\n",
    "# Generate small patches from images at different scales\n",
    "# \n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np \n",
    "import cv2\n",
    "\n",
    "def savePatches(patcharray, fileName = './DnCNN/numpyData/cleanTrain400Patches.npy'):\n",
    "    numpyPatcharray = np.array(patcharray, dtype='uint8')\n",
    "    np.save(fileName, numpyPatcharray)\n",
    "    \n",
    "def augmentData(img, mode=0):\n",
    "    if mode == 0:\n",
    "        return img\n",
    "    elif mode == 1:\n",
    "        return np.flipud(img)\n",
    "    elif mode == 2:\n",
    "        return np.rot90(img, np.random.randint(1,5))\n",
    "    elif mode == 3:\n",
    "        return np.flipud(np.rot90(img, np.random.randint(1,5)))\n",
    "    elif mode == 4:\n",
    "        return np.fliplr(img)\n",
    "    elif mode == 5:\n",
    "        return np.fliplr(np.rot90(img, np.random.randint(1,5)))\n",
    "\n",
    "def makePatches(file_name):\n",
    "    # I am aware that all this can also be done using skimage and sklearn\n",
    "    patchSize, stride = 64, 10\n",
    "    img = cv2.imread(file_name, 0)\n",
    "    h, w = img.shape\n",
    "    scales = [1, 0.9, 0.8, 0.7, 0.6, 0.5]\n",
    "    patches = []\n",
    "    \n",
    "    for s in scales:\n",
    "        print(\"scale:\", s)\n",
    "        resized_h, resized_w = int(h*s),int(w*s)\n",
    "        if True: # if h == 256 and w == 256: # this is to filter out any images not 256x256 pixels.\n",
    "                resizedImage = cv2.resize(img, (resized_h,resized_w), interpolation=cv2.INTER_CUBIC)\n",
    "                for i in range(0, resized_h-patchSize+1, stride):\n",
    "                    for j in range(0, resized_w-patchSize+1, stride):\n",
    "                        x = resizedImage[i:i+patchSize, j:j+patchSize]\n",
    "\n",
    "                        for k in range(0, 1):\n",
    "                            augmentedPatch = augmentData(x, mode=np.random.randint(0,5))\n",
    "                            patches.append(augmentedPatch)\n",
    "    \n",
    "    return patches\n",
    "\n",
    "TRAIN_IMAGES = glob.glob('./DnCNN/testsets/Train400/*.png')\n",
    "patchArray = []\n",
    "\n",
    "for i, fileName in enumerate(TRAIN_IMAGES):\n",
    "    print(fileName)\n",
    "    patches = makePatches(fileName)\n",
    "    patchArray = patchArray + patches\n",
    "    \n",
    "savePatches(patchArray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# arXiv:1608.03981v1 [cs.CV] 13 Aug 2016#\n",
    "# Beyond a Gaussian Denoiser: Residual Learning of\n",
    "# Deep CNN for Image Denoising\n",
    "# Kai Zhang, Wangmeng Zuo, Yunjin Chen, Deyu Meng, and Lei Zhang\n",
    "# \n",
    "# Author: Olaf Christ\n",
    "# Email: christ_o@gmx.de\n",
    "#\n",
    "# Train the network on the patches and denoise a picture.\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from PIL import Image as pil_image\n",
    "\n",
    "# From tf.keras documentation\n",
    "# This function keeps the learning rate at 0.001 for the first ten epochs\n",
    "# and decreases it exponentially after that.\n",
    "def scheduler(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.001 * tf.math.exp(0.1 * (10 - epoch))\n",
    "\n",
    "lLrScheduler = LearningRateScheduler(scheduler)    \n",
    "    \n",
    "def trainingDatagenerator(y_, batch_size=8):\n",
    "    \n",
    "    # y_ are the clean images\n",
    "    indices = list(range(y_.shape[0]))\n",
    "    while(True):\n",
    "        np.random.shuffle(indices)\n",
    "        for i in range(0, len(indices), batch_size):\n",
    "            batch_y = y_[indices[i:i+batch_size]]\n",
    "            noise =  np.random.normal(0, 0.1, batch_y.shape)\n",
    "            batch_x = batch_y + noise  #add some noise to the clean batch\n",
    "            yield batch_x, batch_y\n",
    "            \n",
    "def loadPatches(fileName = './DnCNN/numpyData/cleanTrain400Patches.npy'):\n",
    "    patcharray = np.load(fileName)\n",
    "    patcharray = patcharray.reshape((patcharray.shape[0],patcharray.shape[1],patcharray.shape[2],1))\n",
    "    patcharray = patcharray.astype('float32')/255.0\n",
    "    return patcharray            \n",
    "\n",
    "#aModelCheckpoint = ModelCheckpoint('./DnCNN', monitor='val_loss', verbose=0, save_best_only=False,\n",
    "#    save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "\n",
    "patchData = loadPatches()\n",
    "\n",
    "\n",
    "INPUT_SHAPE = (None,None,1)\n",
    "inputs = Input(shape=INPUT_SHAPE, name='encoder_input')\n",
    "aDnCNN = DnCNN(depth=5)\n",
    "denoisingCNNModel = aDnCNN.build(anInput = inputs)\n",
    "denoisingCNNModel.summary()\n",
    "denoisingCNNModel.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "batchSize = 128\n",
    "history = denoisingCNNModel.fit(trainingDatagenerator(patchData, batch_size = batchSize), callbacks=[lLrScheduler],\n",
    "                                steps_per_epoch=len(patchData)//batchSize, epochs = 5)\n",
    "\n",
    "# save the final model\n",
    "denoisingCNNModel.save('./DnCNN/DnCNN_Model/DnCNN_Model.h5') \n",
    "\n",
    "#test the network \n",
    "cleanImageArray = np.array(pil_image.open('./DnCNN/testsets/Set12/01.png'), dtype='float32') / 255.0\n",
    "noisyImageArray = cleanImageArray + np.random.normal(0, 0.1, cleanImageArray.shape)\n",
    "noisyImageArray = noisyImageArray.astype('float32')\n",
    "y_predict = denoisingCNNModel.predict(noisyImageArray.reshape(1, noisyImageArray.shape[0], noisyImageArray.shape[1], 1))\n",
    "outputImageArray = y_predict.reshape(cleanImageArray.shape)\n",
    "outputImageArray = np.clip(outputImageArray, 0, 1)\n",
    "\n",
    "noiseImage = pil_image.fromarray((noisyImageArray*255).astype('uint8'))\n",
    "cleanImage = pil_image.fromarray((cleanImageArray*255).astype('uint8'))\n",
    "outputImage = pil_image.fromarray((outputImageArray*255).astype('uint8'))\n",
    "cleanImage.show()\n",
    "outputImage.show()\n",
    "noiseImage.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arXiv:1608.03981v1 [cs.CV] 13 Aug 2016#\n",
    "# Beyond a Gaussian Denoiser: Residual Learning of\n",
    "# Deep CNN for Image Denoising\n",
    "# Kai Zhang, Wangmeng Zuo, Yunjin Chen, Deyu Meng, and Lei Zhang\n",
    "# \n",
    "# Author: Olaf Christ\n",
    "# Email: christ_o@gmx.de\n",
    "#\n",
    "# Use TFLite to denoise images\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image as pil_image\n",
    "import numpy as np\n",
    "\n",
    "#DnCNN_Model_cleanTrain400Patches_256x256 has been created with input shape 256,256,1 to avoid a conversion error\n",
    "model = model = load_model('./DnCNN/DnCNN_Model/DnCNN_Model_cleanTrain400Patches_256x256.h5')\n",
    "#convert to tflite and save to disk\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(\"./DnCNN/DnCNN_Model/DnCNN_Model_cleanTrain400Patches_256x25.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the TensorFlow Lite model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "#test the network \n",
    "cleanImageArray = np.array(pil_image.open('./DnCNN/testsets/Set12/01.png'), dtype='float32') / 255.0\n",
    "noisyImageArray = cleanImageArray + np.random.normal(0, 0.1, cleanImageArray.shape)\n",
    "noisyImageArray = noisyImageArray.astype('float32')\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], noisyImageArray.reshape(1, noisyImageArray.shape[0], noisyImageArray.shape[1], 1))\n",
    "interpreter.invoke()\n",
    "\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
    "outputImageArray=tflite_results[0].reshape(256,256)\n",
    "outputImage = pil_image.fromarray((outputImageArray*255).astype('uint8'))\n",
    "noiseImage = pil_image.fromarray((noisyImageArray*255).astype('uint8'))\n",
    "cleanImage = pil_image.fromarray((cleanImageArray*255).astype('uint8'))\n",
    "\n",
    "cleanImage.show()\n",
    "outputImage.show()\n",
    "noiseImage.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an implementation of the 2016 paper \n",
    "# \"Image Restoration Using Convolutional Auto-encoders with Symmetric Skip Connections\"\n",
    "# https://arxiv.org/pdf/1606.08921v3.pdf\n",
    "# Author: Olaf Christ\n",
    "# Email: christ_o@gmx.de\n",
    "\n",
    "from tensorflow.keras.layers import Activation, Dense, Input\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, SpatialDropout2D, ReLU\n",
    "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "#this fixes issues present on my system\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "#This fixes issues with cuDNN\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "InteractiveSession(config=config).close()\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "#this fixes out of memory errors\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K \n",
    "import gc\n",
    "K.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "class AutoEncoder(object):\n",
    "    def __init__(self,\n",
    "                 activation = 'relu',\n",
    "                 dropout_rate = 0.2,\n",
    "                 filterSize = 32,\n",
    "                 skipIndices = set([9,8]),\n",
    "                 numberOfLayers = 10,\n",
    "                 encoderFilters = [64, 32, 16, 8],\n",
    "                 decoderFilters = [64, 32, 16, 8],\n",
    "                 kernel_size = (3, 3),\n",
    "                 strides=(1, 1),\n",
    "                 padding = 'same',\n",
    "                 data_format=\"channels_last\",\n",
    "                 dilation_rate=(1, 1),\n",
    "                 use_bias=False,\n",
    "                 kernel_initializer='he_normal',\n",
    "                 bias_initializer=None,\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=max_norm(2.0),\n",
    "                 bias_constraint=None):\n",
    "        \n",
    "        self.skipIndices = skipIndices\n",
    "        self.numberOfLayers = numberOfLayers\n",
    "        self.filtersize = filterSize\n",
    "        self.encoderFilters = encoderFilters\n",
    "        self.decoderFilters = decoderFilters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.activation = activation\n",
    "        self.padding = padding\n",
    "        self.data_format = data_format\n",
    "        self.dilation_rate = dilation_rate\n",
    "        self.use_bias = use_bias\n",
    "        self.bias_initializer = bias_initializer\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.kernel_regularizer = kernel_regularizer\n",
    "        self.bias_regularizer = bias_regularizer\n",
    "        self.activity_regularizer = activity_regularizer\n",
    "        self.kernel_constraint = kernel_constraint\n",
    "        self.bias_constraint = bias_constraint\n",
    "        self.conv_id=1\n",
    "   \n",
    "    def _buildAutoencoderWithSkipConnecions(self, inputs):\n",
    "                convLayerList = list()\n",
    "                x = inputs\n",
    "                id = 0\n",
    "                for layers in range(self.numberOfLayers):\n",
    "                    x = self._makeConvBlock(self.filtersize, x, f'conv{id}')\n",
    "                    x = SpatialDropout2D(self.dropout_rate)(x)\n",
    "                    convLayerList.append(x)\n",
    "                    id = id + 1\n",
    "                y = x   \n",
    "                id = 0\n",
    "\n",
    "                for layers in range(self.numberOfLayers):\n",
    "                    y = self._makeDeconvBlock(self.filtersize, y, f'deconv{id}')\n",
    "                    y = SpatialDropout2D(self.dropout_rate)(y)\n",
    "                    if id in self.skipIndices:\n",
    "                        layer1 = convLayerList[self.numberOfLayers-id*2-2]\n",
    "                        layer2 = y\n",
    "                        y = self._addSkipConnectionLayer(layer1,layer2,f'skipId{id}')\n",
    "                    id = id + 1\n",
    "                y = Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')(y)\n",
    "                return y\n",
    "           \n",
    "       \n",
    "    def _getLayerList(model):\n",
    "        return [layer for layer in model.layers], [layer.output for layer in model.layers]\n",
    "   \n",
    "    def _makeConvBlock(self, filters, layer, name):\n",
    "        _layer = layer\n",
    "        \n",
    "        _layer = Conv2D(filters = filters,\n",
    "                   kernel_size = self.kernel_size,\n",
    "                   strides= self.strides,\n",
    "                   padding= self.padding,\n",
    "                   data_format=self.data_format,\n",
    "                   dilation_rate=self.dilation_rate,\n",
    "                   activation=self.activation,\n",
    "                   use_bias=self.use_bias,\n",
    "                   kernel_initializer=self.kernel_initializer,\n",
    "                   bias_initializer=self.bias_initializer,\n",
    "                   kernel_regularizer=self.kernel_regularizer,\n",
    "                   bias_regularizer=self.bias_regularizer,\n",
    "                   activity_regularizer=self.activity_regularizer,\n",
    "                   kernel_constraint=self.kernel_constraint,\n",
    "                   bias_constraint=self.bias_constraint,\n",
    "                   name=name)(_layer)\n",
    "        return _layer\n",
    "       \n",
    "    def _makeDeconvBlock(self, filters, layer, name):\n",
    "        _layer = layer\n",
    "        _layer = Conv2DTranspose(filters = filters,\n",
    "                   kernel_size = self.kernel_size,\n",
    "                   strides= self.strides,\n",
    "                   padding= self.padding,\n",
    "                   data_format=self.data_format,\n",
    "                   dilation_rate=self.dilation_rate,\n",
    "                   activation=self.activation,\n",
    "                   use_bias=self.use_bias,\n",
    "                   kernel_initializer=self.kernel_initializer,\n",
    "                   bias_initializer=self.bias_initializer,\n",
    "                   kernel_regularizer=self.kernel_regularizer,\n",
    "                   bias_regularizer=self.bias_regularizer,\n",
    "                   activity_regularizer=self.activity_regularizer,\n",
    "                   kernel_constraint=self.kernel_constraint,\n",
    "                   bias_constraint=self.bias_constraint,\n",
    "                   name=name)(_layer)\n",
    "        return _layer\n",
    "   \n",
    "    def _buildDeconv(self,inputs):\n",
    "        x = inputs\n",
    "        id = 1\n",
    "        for filters in self.decoderFilters[::-1]:\n",
    "            x = Conv2DTranspose(filters = filters,\n",
    "                   kernel_size = self.kernel_size,\n",
    "                   strides= self.strides,\n",
    "                   padding= self.padding,\n",
    "                   data_format=self.data_format,\n",
    "                   dilation_rate=self.dilation_rate,\n",
    "                   activation=self.activation,\n",
    "                   use_bias=self.use_bias,\n",
    "                   kernel_initializer=self.kernel_initializer,\n",
    "                   bias_initializer=self.bias_initializer,\n",
    "                   kernel_regularizer=self.kernel_regularizer,\n",
    "                   bias_regularizer=self.bias_regularizer,\n",
    "                   activity_regularizer=self.activity_regularizer,\n",
    "                   kernel_constraint=self.kernel_constraint,\n",
    "                   bias_constraint=self.bias_constraint,\n",
    "                   name=f'deconv{id}')(x)\n",
    "            id = id + 1\n",
    "        x = SpatialDropout2D(self.dropout_rate)(x)\n",
    "        return x   \n",
    "       \n",
    "    def _buildConv(self, inputs):\n",
    "        x = inputs\n",
    "        id = 1\n",
    "        for filters in self.encoderFilters:\n",
    "            x = Conv2D(filters = filters,\n",
    "                   kernel_size = self.kernel_size,\n",
    "                   strides= self.strides,\n",
    "                   padding= self.padding,\n",
    "                   data_format=self.data_format,\n",
    "                   dilation_rate=self.dilation_rate,\n",
    "                   activation=self.activation,\n",
    "                   use_bias=self.use_bias,\n",
    "                   kernel_initializer=self.kernel_initializer,\n",
    "                   bias_initializer=self.bias_initializer,\n",
    "                   kernel_regularizer=self.kernel_regularizer,\n",
    "                   bias_regularizer=self.bias_regularizer,\n",
    "                   activity_regularizer=self.activity_regularizer,\n",
    "                   kernel_constraint=self.kernel_constraint,\n",
    "                   bias_constraint=self.bias_constraint,\n",
    "               name=f'conv{id}')(x)\n",
    "            id = id + 1\n",
    "        x = SpatialDropout2D(self.dropout_rate)(x)  \n",
    "        return x\n",
    "   \n",
    "    def makeAutoencoderModelWithSkipConnecions(self,inputs):\n",
    "        encoded = self._buildAutoencoderWithSkipConnecions(inputs=inputs)\n",
    "        return Model(inputs=inputs, outputs=encoded, name=\"AutoencoderModel\")\n",
    "   \n",
    "    def makeDecoderModel(self,inputs):\n",
    "        decoded = self._buildDeconv(inputs=inputs)\n",
    "        return Model(inputs=inputs, outputs=decoded, name=\"DecoderModel\")\n",
    "   \n",
    "    def makeEncoderModel(self,inputs):\n",
    "        encoded = self._buildConv(inputs=inputs)\n",
    "        return Model(inputs=inputs, outputs=encoded, name=\"EncoderModel\")\n",
    "   \n",
    "    def _addSkipConnectionLayer(self,input1, input2, name):\n",
    "        x = tf.keras.layers.add([input1, input2])\n",
    "        return ReLU(name=name)(x)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This is an implementation of the 2016 paper \n",
    "# \"Image Restoration Using Convolutional Auto-encoders with Symmetric Skip Connections\"\n",
    "# https://arxiv.org/pdf/1606.08921v3.pdf\n",
    "# Author: Olaf Christ\n",
    "# Email: christ_o@gmx.de\n",
    "# Copyright (C) Olaf Christ 2020, All rights reserved\n",
    "#\n",
    "# Train the autoencoder on MNIST\n",
    "#\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# the code to load the MNIST dataset is adapted from\n",
    "# https://www.machinecurve.com/index.php/2019/12/20/building-an-image-denoiser-with-a-keras-autoencoder-neural-network/\n",
    "img_width, img_height = 28, 28\n",
    "noise_factor = 0.75\n",
    "\n",
    "# Load MNIST dataset\n",
    "(input_train, target_train), (input_test, target_test) = mnist.load_data()\n",
    "\n",
    "input_train = input_train.reshape(input_train.shape[0], img_width, img_height, 1)\n",
    "input_test = input_test.reshape(input_test.shape[0], img_width, img_height, 1)\n",
    "input_shape = (img_width, img_height, 1)\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Add noise\n",
    "pure = input_train\n",
    "pure_test = input_test\n",
    "noise = np.random.normal(0, 1, pure.shape)\n",
    "noise_test = np.random.normal(0, 1, pure_test.shape)\n",
    "noisy_input = pure + noise_factor * noise\n",
    "noisy_input_test = pure_test + noise_factor * noise_test\n",
    "batch_size = 64\n",
    "\n",
    "# Network parameters\n",
    "INPUT_SHAPE = (img_width, img_height, 1)\n",
    "inputs = Input(shape=INPUT_SHAPE, name='encoder_input')\n",
    "conv2DStackOfLayers = AutoEncoder(skipIndices = set([14]),numberOfLayers = 15)\n",
    "autoEncoderModel = conv2DStackOfLayers.makeAutoencoderModelWithSkipConnecions(inputs=inputs)\n",
    "autoEncoderModel.summary()\n",
    "autoEncoderModel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#stop training if val_accuracy doesn't improve for 10 epochs.\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', mode='max', patience=10)\n",
    "\n",
    "# Train the autoencoder\n",
    "history = autoEncoderModel.fit(noisy_input, pure,\n",
    "                validation_split=0.2,\n",
    "                epochs=30,\n",
    "                batch_size=batch_size,\n",
    "                callbacks=[earlystop_callback])\n",
    "\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "number_of_visualizations = 4\n",
    "\n",
    "# Generate denoised images\n",
    "samples = noisy_input_test[:number_of_visualizations]\n",
    "targets = target_test[:number_of_visualizations]\n",
    "denoised_images = autoEncoderModel.predict(samples)\n",
    "\n",
    "# Plot denoised images\n",
    "for i in range(0, number_of_visualizations):\n",
    "  # Get the sample and the reconstruction\n",
    "      noisy_image = noisy_input_test[i][:, :, 0]\n",
    "      pure_image  = pure_test[i][:, :, 0]\n",
    "      denoised_image = denoised_images[i][:, :, 0]\n",
    "      input_class = targets[i]\n",
    "      # Matplotlib preparations\n",
    "      fig, axes = plt.subplots(1, 3)\n",
    "      fig.set_size_inches(8, 3.5)\n",
    "      # Plot sample and reconstruciton\n",
    "      axes[0].imshow(noisy_image)\n",
    "      axes[0].set_title('Noisy image')\n",
    "      axes[1].imshow(pure_image)\n",
    "      axes[1].set_title('Pure image')\n",
    "      axes[2].imshow(denoised_image)\n",
    "      axes[2].set_title('Denoised image')\n",
    "      fig.suptitle(f'MNIST target = {input_class}')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is an implementation of the 2016 paper \n",
    "# \"Image Restoration Using Convolutional Auto-encoders with Symmetric Skip Connections\"\n",
    "# https://arxiv.org/pdf/1606.08921v3.pdf\n",
    "# Author: Olaf Christ\n",
    "# Email: christ_o@gmx.de\n",
    "# Copyright (C) Olaf Christ 2020, All rights reserved\n",
    "#\n",
    "# Train the autoencoder on 256x256 patches randomly extracted from larger images\n",
    "#\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "# This fixes Cuda issues on my installation\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "InteractiveSession(config=config).close()\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "from tensorflow.keras import backend as K \n",
    "import gc\n",
    "K.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction import image\n",
    "from tensorflow.keras.preprocessing import image as tf_Image\n",
    "from PIL import Image as pil_image\n",
    "\n",
    "#take a few images and randomly sample patches from those images\n",
    "TRAIN_IMAGES = glob.glob('./monkey_images/fullImagesGrayscale/*.jpg')\n",
    "training_data_clean = np.zeros((8000, 256, 256, 1))\n",
    "\n",
    "#prepare clean data \n",
    "cnt = 0\n",
    "for i, fig in enumerate(TRAIN_IMAGES):\n",
    "    one_image = tf_Image.load_img(fig, color_mode='grayscale')\n",
    "    custom_image = tf_Image.img_to_array(one_image).astype('float32')\n",
    "    random_patches = image.extract_patches_2d(custom_image, (256, 256), max_patches = 2000)\n",
    "    for x in range(2000):\n",
    "        img = pil_image.fromarray(random_patches[x])\n",
    "        data = tf_Image.img_to_array(img).astype('float32')\n",
    "        data = data/256.0\n",
    "        training_data_clean[x+cnt] = data\n",
    "    cnt = cnt + 2000   \n",
    "\n",
    "\n",
    "# Add noise\n",
    "noise_factor = 0.15\n",
    "pure = training_data_clean\n",
    "noise = np.random.normal(0, 1, pure.shape)\n",
    "noisy_input = pure + noise_factor * noise\n",
    "batch_size = 8\n",
    "\n",
    "#display clean patch\n",
    "img2 = tf_Image.array_to_img(pure[0], data_format = 'channels_last')\n",
    "img2.show()\n",
    "\n",
    "#display clean noisy patch\n",
    "img3 = tf_Image.array_to_img(noisy_input[0], data_format = 'channels_last')\n",
    "img3.show()\n",
    "\n",
    "# Network parameters\n",
    "INPUT_SHAPE = (256, 256, 1)\n",
    "inputs = Input(shape=INPUT_SHAPE, name='encoder_input')\n",
    "conv2DStackOfLayers = AutoEncoder(numberOfLayers = 5, skipIndices = set())\n",
    "autoEncoderModel = conv2DStackOfLayers.makeAutoencoderModelWithSkipConnecions(inputs=inputs)\n",
    "autoEncoderModel.summary()\n",
    "optimizer = Adam(lr=0.001)\n",
    "autoEncoderModel.compile(optimizer=optimizer, loss='mse', metrics=['accuracy'])\n",
    "\n",
    "history = autoEncoderModel.fit(noisy_input, pure, validation_split=0.2,             \n",
    "                epochs=30,\n",
    "                batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
